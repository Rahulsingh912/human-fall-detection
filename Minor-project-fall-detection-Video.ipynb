{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "348b7b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "787c8e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"F:/Download/best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0718f566",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 1351.0ms\n",
      "Speed: 190.2ms preprocess, 1351.0ms inference, 31.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 363.7ms\n",
      "Speed: 16.9ms preprocess, 363.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 322.9ms\n",
      "Speed: 0.0ms preprocess, 322.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 340.0ms\n",
      "Speed: 17.4ms preprocess, 340.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 fall, 396.5ms\n",
      "Speed: 5.1ms preprocess, 396.5ms inference, 104.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 fall, 348.1ms\n",
      "Speed: 8.1ms preprocess, 348.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 fall, 387.0ms\n",
      "Speed: 5.2ms preprocess, 387.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 falls, 456.4ms\n",
      "Speed: 8.5ms preprocess, 456.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 falls, 413.0ms\n",
      "Speed: 4.0ms preprocess, 413.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 fall, 285.8ms\n",
      "Speed: 12.7ms preprocess, 285.8ms inference, 17.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 falls, 332.2ms\n",
      "Speed: 13.6ms preprocess, 332.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 fall, 329.0ms\n",
      "Speed: 10.7ms preprocess, 329.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 340.5ms\n",
      "Speed: 19.6ms preprocess, 340.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 298.0ms\n",
      "Speed: 11.9ms preprocess, 298.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 306.9ms\n",
      "Speed: 22.1ms preprocess, 306.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 308.5ms\n",
      "Speed: 8.6ms preprocess, 308.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 302.2ms\n",
      "Speed: 0.0ms preprocess, 302.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 340.9ms\n",
      "Speed: 5.6ms preprocess, 340.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    results = model(frame, show=False, stream=True)\n",
    "    \n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "        for box in boxes:\n",
    "            if box.conf < 0.4:\n",
    "                continue\n",
    "            if int(box.cls) == 1:\n",
    "                x1, y1, x2, y2 = box.xyxy[0]\n",
    "                x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "                cv2.putText(frame, f'{model.names[int(box.cls)]} {float(box.conf):.2f}',\n",
    "                            (x1, y1-20), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 0, 255), 2)\n",
    "            \n",
    "            \n",
    "    cv2.imshow(\"frame\", frame)\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f679ff33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
